{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6dcfbf6-e30a-4759-99ee-637f31563ec2",
   "metadata": {},
   "source": [
    "1.\tSkill overlap scoring\n",
    "2.\tAuto JD skill extraction\n",
    "3.\tMust-have vs nice-to-have filtering\n",
    "4.\tCandidate profile cards\n",
    "5.\tReverse JD matching (two-sided mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae0b45-9405-40e5-972e-5dbe841b34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- CONFIG & SETUP ---\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_6ANMxB_NBF6TZziCKrn6kWNDskfdQzUj5GU7AJYtFWkWwsRefuXBdrJxRSxrvRe1Y2Nbi2\"  # <-- Replace with your key\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# Resume index\n",
    "RESUME_INDEX = \"resume-index\"\n",
    "# JD index\n",
    "JD_INDEX = \"jd-index\"\n",
    "\n",
    "\n",
    "# Embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# VectorStores\n",
    "resume_store = PineconeVectorStore(index_name=RESUME_INDEX, embedding=embedding_model)\n",
    "jd_store     = PineconeVectorStore(index_name=JD_INDEX,     embedding=embedding_model)\n",
    "\n",
    "# LLM for QA / query responses\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "pipe      = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=256)\n",
    "llm       = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Retrieval chain for recruiter mode\n",
    "resume_retriever = resume_store.as_retriever()\n",
    "qa_chain         = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=resume_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "# NER model for skill extraction\n",
    "ner_model = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "\n",
    "def extract_skills_hf(text):\n",
    "    ents = ner_model(text)\n",
    "    return list({e[\"word\"] for e in ents if e[\"entity_group\"] in [\"ORG\", \"MISC\"]})\n",
    "\n",
    "def extract_skills_from_text(text):\n",
    "    # same as above but alias for JD\n",
    "    return extract_skills_hf(text)\n",
    "\n",
    "# --- STREAMLIT UI ---\n",
    "st.set_page_config(page_title=\"AI Resume Matcher\", page_icon=\"ðŸ§ \", layout=\"wide\")\n",
    "st.title(\"ðŸ§  AI Resume Matcher with HuggingFace + Pinecone\")\n",
    "\n",
    "# Mode switcher\n",
    "mode = st.radio(\n",
    "    \"ðŸ§­ Select Mode:\",\n",
    "    [\"Recruiter: Match JD â†’ Resumes\", \"Candidate: Match Resume â†’ JDs\"],\n",
    "    horizontal=True\n",
    ")\n",
    "\n",
    "# Sidebar: Cleanup Tools and Skill Filter\n",
    "with st.sidebar:\n",
    "    st.markdown(\"## ðŸ§¹ Cleanup Tools\")\n",
    "    with st.expander(\"âš ï¸ Reset Indexes\"):\n",
    "        st.warning(\"This will permanently delete and recreate both Pinecone indexes.\")\n",
    "        confirm = st.checkbox(\"I understand and want to proceed\")\n",
    "        pwd     = st.text_input(\"Admin password:\", type=\"password\")\n",
    "        if confirm and pwd:\n",
    "            if pwd == \"123\":\n",
    "                if st.button(\"âŒ Confirm Full Reset\"):\n",
    "                    with st.spinner(\"Resetting indexes...\"):\n",
    "                        for idx in [RESUME_INDEX, JD_INDEX]:\n",
    "                            pc.delete_index(idx)\n",
    "                            pc.create_index(\n",
    "                                name=idx,\n",
    "                                dimension=384,\n",
    "                                metric=\"cosine\",\n",
    "                                spec={\"cloud\": \"aws\", \"region\": \"us-east-1\"}\n",
    "                            )\n",
    "                        st.success(\"âœ… Both indexes cleared and recreated.\")\n",
    "            else:\n",
    "                st.error(\"ðŸš« Incorrect password.\")\n",
    "\n",
    "    st.markdown(\"## ðŸŽ¯ Global Skill Filter\")\n",
    "    # Define a superset or derive from JD store later\n",
    "    ALL_SKILLS = [\"Python\",\"Docker\",\"Streamlit\",\"LangChain\",\"Pinecone\",\"Transformers\",\"Kubernetes\"]\n",
    "    selected_skill = st.selectbox(\"Filter candidates by skill:\", [\"Show All\"] + ALL_SKILLS)\n",
    "\n",
    "# --- RECRUITER MODE: JD â†’ Resumes ---\n",
    "if mode == \"Recruiter: Match JD â†’ Resumes\":\n",
    "    st.header(\"ðŸ“¥ Upload & Index Resumes\")\n",
    "    uploaded = st.file_uploader(\"Upload .txt or .pdf resumes\", type=[\"txt\",\"pdf\"], accept_multiple_files=True)\n",
    "    if uploaded:\n",
    "        for f in uploaded:\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".\"+f.name.split(\".\")[-1]) as tmp:\n",
    "                tmp.write(f.getvalue())\n",
    "                path = tmp.name\n",
    "            loader = TextLoader(path) if f.name.endswith(\".txt\") else PyPDFLoader(path)\n",
    "            docs = loader.load()\n",
    "            candidate = f.name.rsplit(\".\",1)[0]\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"candidate_name\"] = candidate\n",
    "                snippet = doc.page_content[:1000]\n",
    "                doc.metadata[\"skills\"] = extract_skills_hf(snippet)\n",
    "            chunks = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50).split_documents(docs)\n",
    "            PineconeVectorStore.from_documents(documents=chunks, embedding=embedding_model, index_name=RESUME_INDEX)\n",
    "            st.success(f\"Indexed {f.name}\")\n",
    "\n",
    "    st.header(\"ðŸ“¥ Upload & Index Job Descriptions\")\n",
    "    jd_files = st.file_uploader(\"Upload .txt JDs\", type=[\"txt\"], accept_multiple_files=True, key=\"jd_up\")\n",
    "    if jd_files:\n",
    "        for f in jd_files:\n",
    "            text = f.read().decode(\"utf-8\")\n",
    "            from langchain.schema import Document\n",
    "            doc = Document(page_content=text, metadata={\"jd_name\": f.name})\n",
    "            chunks = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50).split_documents([doc])\n",
    "            PineconeVectorStore.from_documents(documents=chunks, embedding=embedding_model, index_name=JD_INDEX)\n",
    "            st.success(f\"Indexed JD {f.name}\")\n",
    "\n",
    "    st.header(\"ðŸ“„ Match Candidates by Job Description\")\n",
    "    jd_text = st.text_area(\"Paste a Job Description\")\n",
    "    if jd_text:\n",
    "        # Phase 2: extract JD skills\n",
    "        if st.button(\"ðŸ§  Extract Skills from JD\"):\n",
    "            jd_skills = extract_skills_from_text(jd_text)\n",
    "            st.success(\"Extracted: \" + \", \".join(jd_skills))\n",
    "        try:\n",
    "            jd_skills\n",
    "        except NameError:\n",
    "            jd_skills = []\n",
    "        custom = st.text_input(\"âœï¸ Add/Edit JD skills (comma-separated):\")\n",
    "        if custom:\n",
    "            jd_skills = [s.strip() for s in custom.split(\",\")]\n",
    "\n",
    "        st.subheader(\"ðŸ§ª Skill Filtering\")\n",
    "        must_have = st.multiselect(\"âœ… Must-Have\", jd_skills, default=jd_skills[:2])\n",
    "        nice     = st.multiselect(\"ðŸ‘ Nice-to-Have\", [s for s in jd_skills if s not in must_have])\n",
    "\n",
    "        # embed JD\n",
    "        jd_vec = embedding_model.embed_query(jd_text)\n",
    "        # search top chunks\n",
    "        results = resume_store.similarity_search_with_score(jd_text, k=10)\n",
    "\n",
    "        scored = []\n",
    "        for doc, _ in results:\n",
    "            # semantic\n",
    "            cos = cosine_similarity([jd_vec], [embedding_model.embed_query(doc.page_content)])[0][0]\n",
    "            doc_sk = doc.metadata.get(\"skills\", [])\n",
    "            # filter must-have\n",
    "            if must_have and not set(must_have).issubset(doc_sk):\n",
    "                continue\n",
    "            # overlap scoring\n",
    "            mh = len(set(must_have)&set(doc_sk))\n",
    "            nh = len(set(nice)&set(doc_sk))\n",
    "            ov = (mh + 0.5*nh)/(len(must_have)+len(nice)) if (must_have or nice) else 0\n",
    "            final = 0.7*cos + 0.3*ov\n",
    "            scored.append((doc, final))\n",
    "\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Top 3 dashboard\n",
    "        st.subheader(\"ðŸ† Top 3 Matches\")\n",
    "        for i, (doc, score) in enumerate(scored[:3]):\n",
    "            st.markdown(f\"**{i+1}. {doc.metadata['candidate_name']}** â€” Score: {score:.3f}\")\n",
    "            st.markdown(f\"ðŸ”§ Skills: {', '.join(doc.metadata.get('skills',[]))}\")\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "        # Full list + CSV export\n",
    "        st.subheader(\"ðŸ“‚ All Matches\")\n",
    "        export = []\n",
    "        for i, (doc, score) in enumerate(scored):\n",
    "            sks = doc.metadata.get(\"skills\",[])\n",
    "            if selected_skill!=\"Show All\" and selected_skill not in sks:\n",
    "                continue\n",
    "            st.markdown(f\"**{i+1}. {doc.metadata['candidate_name']}** â€” Score: {score:.3f}\")\n",
    "            st.markdown(f\"ðŸ”§ Skills: {', '.join(sks)}\")\n",
    "            with st.expander(\"ðŸ“„ Snippet\"):\n",
    "                st.write(doc.page_content.strip())\n",
    "            export.append({\n",
    "                \"Rank\": i+1,\n",
    "                \"Candidate\": doc.metadata[\"candidate_name\"],\n",
    "                \"Skills\": \", \".join(sks),\n",
    "                \"Score\": f\"{score:.3f}\",\n",
    "                \"Snippet\": doc.page_content[:200]\n",
    "            })\n",
    "        if export:\n",
    "            df = pd.DataFrame(export)\n",
    "            csv = df.to_csv(index=False).encode(\"utf-8\")\n",
    "            st.download_button(\"ðŸ“¥ Download Matches CSV\", csv, \"matches.csv\", \"text/csv\")\n",
    "\n",
    "# --- CANDIDATE MODE: Resume â†’ JDs ---\n",
    "else:\n",
    "    st.header(\"ðŸ” Upload a Resume to Find Matching Jobs\")\n",
    "    rev = st.file_uploader(\"Upload .txt or .pdf resume\", type=[\"txt\",\"pdf\"], key=\"rev\")\n",
    "    if rev:\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".\"+rev.name.split(\".\")[-1]) as tmp:\n",
    "            tmp.write(rev.getvalue())\n",
    "            path = tmp.name\n",
    "        loader = TextLoader(path) if rev.name.endswith(\".txt\") else PyPDFLoader(path)\n",
    "        text = loader.load()[0].page_content\n",
    "        vec  = embedding_model.embed_query(text)\n",
    "        jd_results = jd_store.similarity_search_with_score(text, k=10)\n",
    "\n",
    "        st.subheader(\"ðŸ… Top Matching JDs\")\n",
    "        for i, (jd_doc, score) in enumerate(jd_results[:5]):\n",
    "            st.markdown(f\"**{i+1}. {jd_doc.metadata.get('jd_name')}** â€” Score: {score:.3f}\")\n",
    "            with st.expander(\"ðŸ“„ Preview JD\"):\n",
    "                st.write(jd_doc.page_content.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai_env)",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
